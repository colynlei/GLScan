//
//  GLScanQRCode.m
//  GLScan
//
//  Created by ã€å›½ã€ ğŸ‡¨ğŸ‡³ on 2020/3/21.
//  Copyright Â© 2020 ã€å›½ã€ ğŸ‡¨ğŸ‡³. All rights reserved.
//

#import "GLScanQRCode.h"
#import <Photos/Photos.h>


@interface GLScanQRCode ()<AVCaptureMetadataOutputObjectsDelegate,AVCaptureVideoDataOutputSampleBufferDelegate>

@property (nonatomic, strong) AVCaptureDevice *device;
@property (nonatomic, strong) AVCaptureDeviceInput *input;
@property (nonatomic, strong) AVCaptureStillImageOutput *stillImageOutput;// ios 9 åŠä»¥ä¸‹
@property (nonatomic, strong) AVCapturePhotoOutput *photoOutput;// iOS 10 åŠä»¥ä¸Š

@property (nonatomic, strong) AVCaptureSession *session;// ä¼šè¯å¯¹è±¡

@property (nonatomic, strong) UIView *captureView;// é¢„è§ˆçˆ¶è§†å›¾
@property (nonatomic, strong) AVCaptureVideoPreviewLayer *previewLayer;// é¢„è§ˆå›¾å±‚

@property (nonatomic, assign) CGFloat maxZoomFactor;// æœ€å¤§ç¼©æ”¾æ¯”ä¾‹
@property (nonatomic, assign) CGFloat minZoomFactor;// æœ€å°ç¼©æ”¾æ¯”ä¾‹
@property (nonatomic, assign) CGFloat currentZoomFactor;// å½“å‰ç¼©æ”¾æ¯”ä¾‹

@property (nonatomic, assign) BOOL bHadAutoVideoZoom;

@end

@implementation GLScanQRCode


#pragma mark - ------< åˆå§‹åŒ– >------
- (instancetype)initWithScanShowView:(UIView *)showView {
    self = [super init];
    if (self) {
        self.showView = showView;
        [self setDefault];
        [self initCapture];
        
        // æ·»åŠ ä¸»é¢˜åŒºåŸŸæ›´æ”¹ç›‘è§†
        // å½“AVCaptureDeviceçš„subjectAreaChangeMonitoringEnabledå±æ€§ä¸ºYESæ—¶æ‰ä¼šå‘é€æ­¤é€šçŸ¥
        // æ›´æ”¹subjectAreaChangeMonitoringEnabledå±æ€§æ—¶éœ€åŠ é”å¤„ç†
        [[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(captureDeviceSubjectAreaDidChangeNotification:) name:AVCaptureDeviceSubjectAreaDidChangeNotification object:self.device];
        
        // å±å¹•æ—‹è½¬é€šçŸ¥
        [[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(statusBarDidChangeFrameNotification:) name:UIApplicationDidChangeStatusBarFrameNotification object:nil];
        
    }
    return self;
}

#pragma mark - ------< è®¾ç½®é»˜è®¤å‚æ•° >------
- (void)setDefault {
    self.isSingleTapAutoFocus = NO;
    self.isDoubleTapScale = NO;
    self.isPinchScale = NO;
    self.bHadAutoVideoZoom = NO;
}

#pragma mark - ------< åˆå§‹åŒ–ç›¸æœºç­‰è¾“å…¥å¯¹è±¡ >------
- (void)initCapture {
    if ([self isAuthority] == NO) return;
    // è·å–æ‘„åƒè®¾å¤‡
    self.device = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];
    // å½“å¯åŠ¨AVCaptureDeviceSubjectAreaDidChangeNotificationé€šçŸ¥æ—¶
    // éœ€å°†subjectAreaChangeMonitoringEnabledæ”¹ä¸ºYES
    [self.device lockForConfiguration:nil];
    self.device.subjectAreaChangeMonitoringEnabled = YES;
    [self.device unlockForConfiguration];
    // è®¾ç½®ä¼šè¯å¯¹è±¡
    self.session = [[AVCaptureSession alloc] init];
    // è®¾ç½®ä¼šè¯é‡‡é›†ç‡
    self.session.sessionPreset = AVCaptureSessionPreset1920x1080;
    
    // åˆ›å»ºæ‘„åƒè®¾å¤‡è¾“å…¥æµ
    self.input = [AVCaptureDeviceInput deviceInputWithDevice:self.device error:nil];
    if ([self.session canAddInput:self.input]) {
        [self.session addInput:self.input];
    }
    
    // åˆ›å»ºå…ƒæ•°æ®è¾“å‡ºæµ
    AVCaptureMetadataOutput *metaDataOutput = [[AVCaptureMetadataOutput alloc] init];
    [metaDataOutput setMetadataObjectsDelegate:self queue:dispatch_get_main_queue()];
    // è®¾ç½®æ‰«æèŒƒå›´ï¼ˆå–å€¼0~1ï¼Œä»¥å±å¹•å³ä¸Šè§’ä¸ºåŸç‚¹ï¼‰
    metaDataOutput.rectOfInterest = CGRectMake(0.05, 0.2, 0.7, 0.6);
    // æ·»åŠ å…ƒæ•°æ®è¾“å‡ºæµåˆ°ä¼šè¯å¯¹è±¡
    if ([self.session canAddOutput:metaDataOutput]) {
        [self.session addOutput:metaDataOutput];
    }
    
    // è·å–æ‰«ç ç±»å‹
//    [metaDataOutput availableMetadataObjectTypes];//æ£€æŸ¥ç±»å‹æ˜¯å¦æœ‰æ•ˆ
    metaDataOutput.metadataObjectTypes = [self getMetadataObjectTypes];
    
    // åˆ›å»ºæ‘„åƒè®¾å¤‡è¾“å‡ºæµï¼Œç”¨äºè¯†åˆ«å…‰çº¿å¼ºå¼±
    AVCaptureVideoDataOutput *videoDataOutput = [[AVCaptureVideoDataOutput alloc] init];
    [videoDataOutput setSampleBufferDelegate:self queue:dispatch_get_main_queue()];
    // æ·»åŠ æ‘„åƒè®¾å¤‡è¾“å‡ºæµåˆ°ä¼šè¯å¯¹è±¡
    if ([self.session canAddOutput:videoDataOutput]) {
        [self.session addOutput:videoDataOutput];
    }
    
    self.stillImageOutput = [[AVCaptureStillImageOutput alloc]init];
    NSDictionary *outputSettings = [[NSDictionary alloc]initWithObjectsAndKeys:AVVideoCodecJPEG,AVVideoCodecKey ,nil];
    [self.stillImageOutput setOutputSettings:outputSettings];
}

#pragma mark - ------< æ‰«ç ç±»å‹ >------
- (NSArray *)getMetadataObjectTypes {
    return @[
        // äºŒç»´ç 
        AVMetadataObjectTypeQRCode,
        // ä»¥ä¸‹æ˜¯æ¡å½¢ç 
        AVMetadataObjectTypeUPCECode,
        AVMetadataObjectTypeEAN8Code,
        AVMetadataObjectTypeEAN13Code,
        AVMetadataObjectTypeAztecCode,
        AVMetadataObjectTypeCode39Code,
        AVMetadataObjectTypeCode93Code,
        AVMetadataObjectTypePDF417Code,
        AVMetadataObjectTypeCode128Code,
        AVMetadataObjectTypeCode39Mod43Code,
    ];
}

#pragma mark - ------< è·å–æœ€å¤§ç¼©æ”¾æ¯”ä¾‹ >------
- (CGFloat)maxZoomFactor {
    CGFloat max = 1;
    if (@available(iOS 11.0, *)) {
        max = self.device.maxAvailableVideoZoomFactor;
    } else {
        max = self.device.activeFormat.videoMaxZoomFactor;
    }
    
    // å¯¹æœ€å¤§ç¼©æ”¾æ¯”ä¾‹å†æ¬¡åšé™åˆ¶
    if (max > 5) {
        max = 5;
    }
    
    return max;
}

#pragma mark - ------< è·å–æœ€å°ç¼©æ”¾æ¯”ä¾‹ >------
- (CGFloat)minZoomFactor {
    CGFloat min = 1;
    if (@available(iOS 11.0, *)) {
        min = self.device.minAvailableVideoZoomFactor;
    }
    return min;
}

#pragma mark - ------< åˆå§‹åŒ–é¢„è§ˆè§†å›¾ >------
- (AVCaptureVideoPreviewLayer *)previewLayer {
    if (!_previewLayer) {
        _previewLayer = [AVCaptureVideoPreviewLayer layerWithSession:self.session];
        _previewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill;
    }
    if (_previewLayer.session == nil) {
        [_previewLayer setSession:self.session];
    }
    return _previewLayer;
}

#pragma mark - ------< é¢„è§ˆè§†å›¾çš„çˆ¶è§†å›¾ï¼Œç”¨äºè‡ªåŠ¨æ”¾å¤§ï¼Œæ‰‹åŠ¿æ”¾å¤§ç­‰>------
- (UIView *)captureView {
    if (!_captureView) {
        _captureView = [[UIView alloc] init];
        _captureView.alpha = 0;
        
        // æ·»åŠ é¢„è§ˆè§†å›¾
        [_captureView.layer addSublayer:self.previewLayer];
        
        // ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ å•å‡»æ‰‹åŠ¿
        UITapGestureRecognizer *singleTap = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(singleTapAction:)];
        [_captureView addGestureRecognizer:singleTap];
        
        // ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ åŒå‡»æ‰‹åŠ¿
        UITapGestureRecognizer *doubleTap = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(doubleTapAction:)];
        doubleTap.numberOfTapsRequired = 2;
        [_captureView addGestureRecognizer:doubleTap];
        
        // ä¼˜å…ˆè§¦å‘åŒå‡»
        [singleTap requireGestureRecognizerToFail:doubleTap];
        
        // ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ ç¼©æ”¾æ‰‹åŠ¿
        UIPinchGestureRecognizer *pinch = [[UIPinchGestureRecognizer alloc] initWithTarget:self action:@selector(pinchAction:)];
        [_captureView addGestureRecognizer:pinch];
    }
    return _captureView;
}

#pragma mark - ------< æŸ¥è¯¢æ˜¯å¦æœ‰ç›¸æœºè®¿é—®æƒé™ >------
- (BOOL)isAuthority {
    AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];
    switch (status) {
        case AVAuthorizationStatusNotDetermined:
            NSLog(@"ç”¨æˆ·å°šæœªè¿›è¡Œæˆæƒä½¿ç”¨ç›¸æœºæ“ä½œ");
            return NO;
            break;
        case AVAuthorizationStatusRestricted:
            NSLog(@"ç›¸æœºè®¿é—®æƒé™å·²è¢«ç¦æ­¢ï¼Œè¯·åœ¨\"è®¾ç½® - éšç§ - ç›¸æœº\"é€‰é¡¹ä¸­ï¼Œå…è®¸å¤šå®¢è®¿é—®æ‚¨çš„ç›¸æœº");
            return NO;
            break;
        case AVAuthorizationStatusDenied:
            NSLog(@"ç›¸æœºè®¿é—®æƒé™å·²è¢«ç¦æ­¢ï¼Œè¯·åœ¨\"è®¾ç½® - éšç§ - ç›¸æœº\"é€‰é¡¹ä¸­ï¼Œå…è®¸å¤šå®¢è®¿é—®æ‚¨çš„ç›¸æœº");
            return NO;
            break;
        case AVAuthorizationStatusAuthorized:
            NSLog(@"ç”¨æˆ·å·²ç»æˆæƒä½¿ç”¨ç›¸æœº");
            return YES;
            break;
            
        default:
            break;
    }
}

#pragma mark - ------< è·å–ç›¸æœºè®¿é—®æƒé™ >------
- (void)getCaptureAuthority {
    [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {
        if (granted) {
            dispatch_async(dispatch_get_main_queue(), ^{
                [self initCapture];
                [self startRunning];
            });
        } else {
            NSLog(@"è¢«ç”¨æˆ·æ‹’ç»");
        }
    }];
}

#pragma mark - ------< AVCaptureMetadataOutputObjectsDelegate >------
- (void)captureOutput:(AVCaptureOutput *)output didOutputMetadataObjects:(nonnull NSArray<__kindof AVMetadataObject *> *)metadataObjects fromConnection:(nonnull AVCaptureConnection *)connection {
    NSLog(@"%@",metadataObjects);
    if (metadataObjects == nil) return;
    NSString *scanText = nil;
    for (AVMetadataMachineReadableCodeObject *obj in metadataObjects) {
        NSString *text = obj.stringValue;
        if (text && text.length) {
            scanText = text;
        }
    }
    if (!self.bHadAutoVideoZoom) {
        AVMetadataMachineReadableCodeObject *obj = (AVMetadataMachineReadableCodeObject*)[self.previewLayer transformedMetadataObjectForMetadataObject:metadataObjects.lastObject];
        dispatch_async(dispatch_get_main_queue(), ^{
            [self changeVideoScale:obj];
        });
        self.bHadAutoVideoZoom  =YES;
        return;
    }
    if (self.delegate && [self.delegate respondsToSelector:@selector(gl_capture:resultText:)]) {
        [self.delegate gl_capture:self resultText:scanText];
    }
}

-(void)changeVideoScale:(AVMetadataMachineReadableCodeObject*)objc{
    NSArray *array = objc.corners;
    CGPoint point = CGPointZero;
    int index = 0;
    CFDictionaryRef dic = (__bridge CFDictionaryRef)(array[index++]);
    // æŠŠå­—å…¸è½¬æ¢ä¸ºç‚¹ï¼Œå­˜åœ¨pointé‡Œï¼ŒæˆåŠŸè¿”å›true å…¶ä»–false
    CGPointMakeWithDictionaryRepresentation(dic, &point);
    CGPoint point2 = CGPointZero;
    CGPointMakeWithDictionaryRepresentation((__bridge CFDictionaryRef)array[2], &point2);
//    self.centerPoint = CGPointMake((point.x + point2.x) / 2, (point.y + point2.y) / 2);
    CGFloat scace = 150/(point2.x-point.x);
    [self setVideoScale:scace];
    
    return;
    
}
-(void)setVideoScale:(CGFloat)scale{
    [self.input.device lockForConfiguration:nil];
    AVCaptureConnection *videoConnection = [self connectionWithMediaType:AVMediaTypeVideo fromConnections:self.stillImageOutput.connections];
    CGFloat maxScaleAndCropfactor = ([[self.stillImageOutput connectionWithMediaType:AVMediaTypeVideo]videoMaxScaleAndCropFactor])/16;
    if (scale > maxScaleAndCropfactor) {
        scale = maxScaleAndCropfactor;
        
    }else if (scale < 1){
        scale = 1;
    }
  
    videoConnection.videoScaleAndCropFactor = scale;
    
    //æ”¾å¤§é¢„è§ˆå›¾
    if ([self.device lockForConfiguration:nil]) {
        [self.device setVideoZoomFactor:1.5];
//        [self.device rampToVideoZoomFactor:1.5 withRate:5];
        [self.device unlockForConfiguration];
    }
}

-(AVCaptureConnection*)connectionWithMediaType:(NSString*)mediaType fromConnections:(NSArray*)connections{
    for (AVCaptureConnection *connection in connections) {
        for (AVCaptureInputPort *port in [connection inputPorts]) {
            if ([[port mediaType] isEqualToString:mediaType]) {
                return connection;
            }
        }
    }
    return nil;
}

#pragma mark - ------< AVCaptureVideoDataOutputSampleBufferDelegate >------
- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(nonnull CMSampleBufferRef)sampleBuffer fromConnection:(nonnull AVCaptureConnection *)connection {
    CFDictionaryRef metadataDict = CMCopyDictionaryOfAttachments(NULL,sampleBuffer, kCMAttachmentMode_ShouldPropagate);
    NSDictionary *metadata = [[NSMutableDictionary alloc] initWithDictionary:(__bridge NSDictionary*)metadataDict];
    CFRelease(metadataDict);
    NSDictionary *exifMetadata = [[metadata objectForKey:(NSString *)kCGImagePropertyExifDictionary] mutableCopy];
    CGFloat brightnessValue = [[exifMetadata objectForKey:(NSString *)kCGImagePropertyExifBrightnessValue] floatValue];
//    NSLog(@"====%f",brightnessValue);
}

#pragma mark - ------< å¼€å¯ä¼šè¯ >------
- (void)startRunning {
    // æŸ¥è¯¢æ˜¯å¦æœ‰ç›¸æœºæƒé™
    if ([self isAuthority] == NO) {
        // æ— æƒé™æ—¶è·å–æƒé™
        [self getCaptureAuthority];
        return;
    }
    if (self.showView == nil) {
        NSLog(@"é¢„è§ˆçˆ¶è§†å›¾ä¸å­˜åœ¨");
        return;
    }
    if (self.session == nil) {
        NSLog(@"ä¼šè¯å¯¹è±¡ä¸å­˜åœ¨");
        return;
    }
    if (self.captureView.superview == nil) {
        [self.showView insertSubview:self.captureView atIndex:0];
        self.captureView.frame = self.showView.bounds;
        self.previewLayer.frame = self.captureView.bounds;
        if (self.captureView.alpha != 1) {
            [UIView animateWithDuration:0.3 animations:^{
                self.captureView.alpha = 1;
            }];
        }
    }
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
        [self.session startRunning];
    });
}

#pragma mark - ------< å…³é—­ä¼šè¯ >------
- (void)stopRunning {
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
        if (self.session.isRunning) {
            [self.session stopRunning];
        }
    });
}

#pragma mark - ------< ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ å•å‡»æ‰‹åŠ¿ >------
- (void)singleTapAction:(UITapGestureRecognizer *)singleTap {
    if (self.isSingleTapAutoFocus == NO || ![self.session isRunning]) return;
    CGPoint tapPoint = [singleTap locationInView:self.captureView];
    [self setFocusCursorWithPoint:tapPoint focusModel:AVCaptureFocusModeAutoFocus];
    
}

#pragma mark - ------< ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ åŒå‡»æ‰‹åŠ¿ >------
- (void)doubleTapAction:(UITapGestureRecognizer *)doubleTap {
    if (self.isDoubleTapScale == NO || ![self.session isRunning]) return;
    CGPoint tapPoint = [doubleTap locationInView:self.captureView];
    [self.device unlockForConfiguration];
    if ([self.device lockForConfiguration:nil]) {
        if ([self.device isFocusModeSupported:AVCaptureFocusModeAutoFocus]) {
            self.device.focusPointOfInterest = tapPoint;
            self.device.focusMode = AVCaptureFocusModeAutoFocus;
        }
        
        [UIView animateWithDuration:0.3 animations:^{
            if (self.device.videoZoomFactor == self.minZoomFactor) {
                [self.device rampToVideoZoomFactor:self.maxZoomFactor withRate:8];
            } else {
                [self.device rampToVideoZoomFactor:self.minZoomFactor withRate:8];
            }
        }completion:^(BOOL finished) {
            [self.device unlockForConfiguration];
        }];
    }
}

#pragma mark - ------< ç»™é¢„è§ˆçˆ¶è§†å›¾æ·»åŠ ç¼©æ”¾æ‰‹åŠ¿ >------
- (void)pinchAction:(UIPinchGestureRecognizer *)pinch {
    if (self.isPinchScale == NO || ![self.session isRunning]) return;
    if (pinch.state == UIGestureRecognizerStateBegan) {
        self.currentZoomFactor = self.device.videoZoomFactor;
    } else if (pinch.state == UIGestureRecognizerStateChanged) {
        CGFloat currentZoomFactor = self.currentZoomFactor * pinch.scale;        
        if (currentZoomFactor < self.maxZoomFactor &&
            currentZoomFactor > self.minZoomFactor) {
            if ([self.device lockForConfiguration:nil]) {
                self.device.videoZoomFactor = currentZoomFactor;

                [self.device unlockForConfiguration];
            }
        }
    }
}

#pragma mark - ------< é€šçŸ¥ >------
#pragma mark - ------< ä¸»é¢˜åŒºåŸŸæ›´æ”¹é€šçŸ¥ >------
- (void)captureDeviceSubjectAreaDidChangeNotification:(NSNotification *)notif {
    CGPoint point = self.captureView.center;
    [self setFocusCursorWithPoint:point focusModel:AVCaptureFocusModeContinuousAutoFocus];
}

- (void)statusBarDidChangeFrameNotification:(NSNotification *)notif {
    self.captureView.frame = self.showView.bounds;
    self.previewLayer.frame = self.captureView.bounds;
}

#pragma mark - ------< è§¦å‘å¯¹ç„¦ >------
- (void)setFocusCursorWithPoint:(CGPoint)point focusModel:(AVCaptureFocusMode)focusModel{
    //å¯¹æ‹ç…§è®¾å¤‡æ“ä½œå‰ï¼Œå…ˆè¿›è¡Œé”å®šï¼Œé˜²æ­¢å…¶ä»–çº¿ç¨‹wè®¿é—®
    NSError *error = nil;
    [self.session beginConfiguration];
    if ([self.device lockForConfiguration:&error]) {
        
        // è·å–èšç„¦ç‚¹
        CGPoint focusPoint = [self.previewLayer captureDevicePointOfInterestForPoint:point];
        
        // è®¾ç½®èšç„¦ç‚¹ï¼Œå¿…é¡»å…ˆè®¾ç½®èšç„¦ç‚¹å†è®¾ç½®èšç„¦æ¨¡å¼
        if ([self.device isFocusPointOfInterestSupported]) {
            self.device.focusPointOfInterest = focusPoint;
        }
        
        // è®¾ç½®èšç„¦æ¨¡å¼
        if ([self.device isFocusModeSupported:focusModel]) {
            self.device.focusMode = focusModel;
        }
        
        [UIView animateWithDuration:0.3 animations:^{
            self.captureView.transform = CGAffineTransformMakeScale(1.1, 1.1);
        }completion:^(BOOL finished) {
            [UIView animateWithDuration:0.3 animations:^{
                self.captureView.transform = CGAffineTransformIdentity;
            } completion:^(BOOL finished) {
                [self.device unlockForConfiguration];
                [self.session commitConfiguration];
            }];
        }];
    }
}

#pragma mark - ------< ä»å›¾ç‰‡ä¸­è·å–äºŒç»´ç  >------
- (NSArray *)getQRCodeFromImage:(UIImage *)image {
    return [self getQRCodeFromImageData:UIImagePNGRepresentation(image)];
}

- (NSArray *)getQRCodeFromImageData:(NSData *)imageData {
    return [GLScanQRCode getQRCodeFromImageData:imageData];
}

+ (NSArray *)getQRCodeFromImage:(UIImage *)image {
    return [GLScanQRCode getQRCodeFromImageData:UIImagePNGRepresentation(image)];
}

+ (NSArray *)getQRCodeFromImageData:(NSData *)imageData {
    if (imageData == nil) {
        return nil;
    }
    CIImage *originImage = [CIImage imageWithData:imageData];
    CIContext *context = [CIContext contextWithOptions:@{kCIContextUseSoftwareRenderer:@(false),kCIContextPriorityRequestLow:@(false)}];
    CIDetector *detector = [CIDetector detectorOfType:CIDetectorTypeQRCode context:context options:@{CIDetectorAccuracy:CIDetectorAccuracyHigh}];
    NSArray *features = [detector featuresInImage:originImage];
    NSMutableArray *results = [NSMutableArray arrayWithCapacity:0];
    for (CIQRCodeFeature *result in features) {
        if (result.messageString.length) {
            [results addObject:result.messageString];
        }
    }
    return results.copy;
}

- (void)dealloc {
    NSLog(@"===== %@ release =====",NSStringFromClass(self.class));
    [[NSNotificationCenter defaultCenter] removeObserver:self];
}

@end
